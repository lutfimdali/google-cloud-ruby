{"id":"table","metadata":{"name":"Table","description":"<h1 id=\"table\">Table</h1>  <p>A named resource representing a BigQuery table that holds zero or more records. Every table is defined by a schema that may contain nested and repeated fields.</p>","source":"lib/gcloud/bigquery/table.rb#L66","resources":[{"title":"Preparing Data for BigQuery","link":"https://cloud.google.com/bigquery/preparing-data-for-bigquery"}],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.create_table \"my_table\" do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend\n\nrow = {\n  \"first_name\" => \"Alice\",\n  \"cities_lived\" => [\n    {\n      \"place\" => \"Seattle\",\n      \"number_of_years\" => 5\n    },\n    {\n      \"place\" => \"Stockholm\",\n      \"number_of_years\" => 6\n    }\n  ]\n}\ntable.insert row"}]},"methods":[{"metadata":{"name":"table_id","description":"<p>A unique ID for this table. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum length is 1,024 characters.</p>","source":"lib/gcloud/bigquery/table.rb#L89","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"dataset_id","description":"<p>The ID of the <code class=\"highlighter-rouge\">Dataset</code> containing this table.</p>","source":"lib/gcloud/bigquery/table.rb#L98","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"project_id","description":"<p>The ID of the <code class=\"highlighter-rouge\">Project</code> containing this table.</p>","source":"lib/gcloud/bigquery/table.rb#L107","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"id","description":"<p>The combined Project ID, Dataset ID, and Table ID for this table, in the format specified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query Reference</a>: <code class=\"highlighter-rouge\">project_name:datasetId.tableId</code>. To use this value in queries see <a data-custom-type=\"bigquery/table#query_id\">#query_id</a>.</p>","source":"lib/gcloud/bigquery/table.rb#L130","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"query_id","description":"<p>The value returned by <a data-custom-type=\"bigquery/table#id\">#id</a>, wrapped in square brackets if the Project ID contains dashes, as specified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query Reference</a>. Useful in queries.</p>","source":"lib/gcloud/bigquery/table.rb#L152","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ndata = bigquery.query \"SELECT name FROM #{table.query_id}\""}]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"name","description":"<p>The name of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L161","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"name=","description":"<p>Updates the name of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L170","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"etag","description":"<p>A string hash of the dataset.</p>","source":"lib/gcloud/bigquery/table.rb#L179","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"api_url","description":"<p>A URL that can be used to access the dataset using the REST API.</p>","source":"lib/gcloud/bigquery/table.rb#L189","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"description","description":"<p>The description of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L199","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"description=","description":"<p>Updates the description of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L209","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"bytes_count","description":"<p>The number of bytes in the table.</p>","source":"lib/gcloud/bigquery/table.rb#L218","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"rows_count","description":"<p>The number of rows in the table.</p>","source":"lib/gcloud/bigquery/table.rb#L228","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"created_at","description":"<p>The time when this table was created.</p>","source":"lib/gcloud/bigquery/table.rb#L238","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"expires_at","description":"<p>The time when this table expires. If not present, the table will persist indefinitely. Expired tables will be deleted and their storage reclaimed.</p>","source":"lib/gcloud/bigquery/table.rb#L250","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"modified_at","description":"<p>The date when this table was last modified.</p>","source":"lib/gcloud/bigquery/table.rb#L261","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"table?","description":"<p>Checks if the table’s type is “TABLE”.</p>","source":"lib/gcloud/bigquery/table.rb#L271","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":null}]},{"metadata":{"name":"view?","description":"<p>Checks if the table’s type is “VIEW”.</p>","source":"lib/gcloud/bigquery/table.rb#L280","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":null}]},{"metadata":{"name":"location","description":"<p>The geographic location where the table should reside. Possible values include EU and US. The default value is US.</p>","source":"lib/gcloud/bigquery/table.rb#L290","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"schema","description":"<p>Returns the table’s schema as hash containing the keys and values returned by the Google Cloud BigQuery <a href=\"https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\">Rest API </a>. This method can also be used to set, replace, or add to the schema by passing a block. See <a data-custom-type=\"bigquery/table/schema\">Table::Schema</a> for available methods. To set the schema by passing a hash instead, use <a data-custom-type=\"bigquery/table#schema=\">#schema=</a>.</p>","source":"lib/gcloud/bigquery/table.rb#L329","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.create_table \"my_table\"\n\ntable.schema do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"}]},"params":[{"name":"replace","types":["Boolean"],"description":"Whether to replace the existing schema with the new schema. If <code class=\"highlighter-rouge\">true</code>, the fields will replace the existing schema. If <code class=\"highlighter-rouge\">false</code>, the fields will be added to the existing schema. When a table already contains data, schema changes must be additive. Thus, the default value is <code class=\"highlighter-rouge\">false</code>.","optional":true,"default":"false","nullable":false},{"name":"yield","types":["block"],"description":"a block for setting the schema","optional":true,"nullable":false},{"name":"yield.schema","types":["Table::Schema"],"description":"the object accepting the schema","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"metadata":{"name":"schema=","description":"<p>Updates the schema of the table. To update the schema using a block instead, use #schema.</p>","source":"lib/gcloud/bigquery/table.rb#L376","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.create_table \"my_table\"\n\nschema = {\n  \"fields\" => [\n    {\n      \"name\" => \"first_name\",\n      \"type\" => \"STRING\",\n      \"mode\" => \"REQUIRED\"\n    },\n    {\n      \"name\" => \"age\",\n      \"type\" => \"INTEGER\",\n      \"mode\" => \"REQUIRED\"\n    }\n  ]\n}\ntable.schema = schema"}]},"params":[{"name":"new_schema","types":["Hash"],"description":"A hash containing keys and values as specified by the Google Cloud BigQuery <a href=\"https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\">Rest API </a> .","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"metadata":{"name":"fields","description":"<p>The fields of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L385","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"headers","description":"<p>The names of the columns in the table.</p>","source":"lib/gcloud/bigquery/table.rb#L397","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"data","description":"<p>Retrieves data from the table.</p>","source":"lib/gcloud/bigquery/table.rb#L428","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ndata = table.data\ndata.each do |row|\n  puts row[\"first_name\"]\nend\nmore_data = table.data token: data.token"}]},"params":[{"name":"token","types":["String"],"description":"Page token, returned by a previous call, identifying the result set.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"Maximum number of results to return.","optional":true,"default":"nil","nullable":true},{"name":"start","types":["Integer"],"description":"Zero-based index of the starting row to read.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Gcloud::Bigquery::Data"],"description":null}]},{"metadata":{"name":"copy","description":"<p>Copies the data from the table to another table. The destination table argument can also be a string identifier as specified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query Reference</a>: <code class=\"highlighter-rouge\">project_name:datasetId.tableId</code>. This is useful for referencing tables in other projects and datasets.</p>","source":"lib/gcloud/bigquery/table.rb#L490","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\ndestination_table = dataset.table \"my_destination_table\"\n\ncopy_job = table.copy destination_table"},{"caption":"<p>Passing a string identifier for the destination table:</p>","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ncopy_job = table.copy \"other-project:other_dataset.other_table\""}]},"params":[{"name":"destination_table","types":["Table","String"],"description":"The destination for the copied data.","optional":false,"nullable":false},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create new tables.</p>  <p>The following values are supported: * <code class=\"highlighter-rouge\">needed</code> - Create the table if it does not exist. * <code class=\"highlighter-rouge\">never</code> - The table must already exist. A ‘notFound’ error is   raised if the table does not exist.","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in the destination table. The default value is <code class=\"highlighter-rouge\">empty</code>.</p>  <p>The following values are supported: * <code class=\"highlighter-rouge\">truncate</code> - BigQuery overwrites the table data. * <code class=\"highlighter-rouge\">append</code> - BigQuery appends the data to the table. * <code class=\"highlighter-rouge\">empty</code> - An error will be returned if the destination table already   contains data.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Gcloud::Bigquery::CopyJob"],"description":null}]},{"metadata":{"name":"extract","description":"<p>Extract the data from the table to a Google Cloud Storage file.</p>","source":"lib/gcloud/bigquery/table.rb#L579","resources":[{"title":"Exporting Data From BigQuery","link":"https://cloud.google.com/bigquery/exporting-data-from-bigquery"}],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nextract_job = table.extract \"gs://my-bucket/file-name.json\",\n                            format: \"json\""}]},"params":[{"name":"extract_url","types":["Gcloud::Storage::File","String","Array<String>"],"description":"The Google Storage file or file URI pattern(s) to which BigQuery should extract the table data.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is <code class=\"highlighter-rouge\">csv</code>.</p>  <p>The following values are supported: * <code class=\"highlighter-rouge\">csv</code> - CSV * <code class=\"highlighter-rouge\">json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a> * <code class=\"highlighter-rouge\">avro</code> - <a href=\"http://avro.apache.org/\">Avro</a>","optional":true,"default":"nil","nullable":true},{"name":"compression","types":["String"],"description":"The compression type to use for exported files. Possible values include <code class=\"highlighter-rouge\">GZIP</code> and <code class=\"highlighter-rouge\">NONE</code>. The default value is <code class=\"highlighter-rouge\">NONE</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Delimiter to use between fields in the exported data. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"header","types":["Boolean"],"description":"Whether to print out a header row in the results. Default is <code class=\"highlighter-rouge\">true</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Gcloud::Bigquery::ExtractJob"],"description":null}]},{"metadata":{"name":"load","description":"<p>Loads data into the table. You can pass a gcloud storage file path or a gcloud storage file instance. Or, you can upload a file directly. See <a href=\"https://cloud.google.com/bigquery/loading-data-post-request#multipart\">Loading Data with a POST Request</a>.</p>  <h3 id=\"a-note-about-large-direct-uploads\">A note about large direct uploads</h3>  <p>You may encounter a Broken pipe (Errno::EPIPE) error when attempting to upload large files. To avoid this problem, add the <a href=\"https://rubygems.org/gems/httpclient\">httpclient</a> gem to your project, and the line (or lines) of configuration shown below. These lines must execute after you require gcloud but before you make your first gcloud connection. The first statement configures <a href=\"https://rubygems.org/gems/faraday\">Faraday</a> to use httpclient. The second statement, which should only be added if you are using a version of Faraday at or above 0.9.2, is a workaround for <a href=\"https://github.com/GoogleCloudPlatform/gcloud-ruby/issues/367\">this gzip issue</a>.</p>","source":"lib/gcloud/bigquery/table.rb#L740","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nload_job = table.load \"gs://my-bucket/file-name.csv\""},{"caption":"<p>Pass a gcloud storage file instance:</p>","code":"require \"gcloud\"\nrequire \"gcloud/storage\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nstorage = gcloud.storage\nbucket = storage.bucket \"my-bucket\"\nfile = bucket.file \"file-name.csv\"\nload_job = table.load file"},{"caption":"<p>Upload a file directly:</p>","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nfile = File.open \"my_data.csv\"\nload_job = table.load file"},{"caption":"","code":"require \"gcloud\"\n\n# Use httpclient to avoid broken pipe errors with large uploads\nFaraday.default_adapter = :httpclient\n\n# Only add the following statement if using Faraday >= 0.9.2\n# Override gzip middleware with no-op for httpclient\nFaraday::Response.register_middleware :gzip =>\n                                        Faraday::Response::Middleware\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery"}]},"params":[{"name":"file","types":["File","Gcloud::Storage::File","String"],"description":"A file or the URI of a Google Cloud Storage file containing data to load into the table.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is <code class=\"highlighter-rouge\">csv</code>.</p>  <p>The following values are supported: * <code class=\"highlighter-rouge\">csv</code> - CSV * <code class=\"highlighter-rouge\">json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a> * <code class=\"highlighter-rouge\">avro</code> - <a href=\"http://avro.apache.org/\">Avro</a> * <code class=\"highlighter-rouge\">datastore_backup</code> - Cloud Datastore backup","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create new tables.</p>  <p>The following values are supported: * <code class=\"highlighter-rouge\">needed</code> - Create the table if it does not exist. * <code class=\"highlighter-rouge\">never</code> - The table must already exist. A ‘notFound’ error is   raised if the table does not exist.","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in the table. The default value is <code class=\"highlighter-rouge\">empty</code>.</p>  <p>The following values are supported: * <code class=\"highlighter-rouge\">truncate</code> - BigQuery overwrites the table data. * <code class=\"highlighter-rouge\">append</code> - BigQuery appends the data to the table. * <code class=\"highlighter-rouge\">empty</code> - An error will be returned if the table already contains   data.","optional":true,"default":"nil","nullable":true},{"name":"projection_fields","types":["Array<String>"],"description":"If the <code class=\"highlighter-rouge\">format</code> option is set to <code class=\"highlighter-rouge\">datastore_backup</code>, indicates which entity properties to load from a Cloud Datastore backup. Property names are case sensitive and must be top-level properties. If not set, BigQuery loads all properties. If any named property isn’t found in the Cloud Datastore backup, an invalid error is returned.","optional":true,"default":"nil","nullable":true},{"name":"jagged_rows","types":["Boolean"],"description":"Accept rows that are missing trailing optional columns. The missing values are treated as nulls. If <code class=\"highlighter-rouge\">false</code>, records with missing trailing columns are treated as bad records, and if there are too many bad records, an invalid error is returned in the job result. The default value is <code class=\"highlighter-rouge\">false</code>. Only applicable to CSV, ignored for other formats.","optional":true,"default":"nil","nullable":true},{"name":"quoted_newlines","types":["Boolean"],"description":"Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file. The default value is <code class=\"highlighter-rouge\">false</code>.","optional":true,"default":"nil","nullable":true},{"name":"encoding","types":["String"],"description":"The character encoding of the data. The supported values are <code class=\"highlighter-rouge\">UTF-8</code> or <code class=\"highlighter-rouge\">ISO-8859-1</code>. The default value is <code class=\"highlighter-rouge\">UTF-8</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Specifices the separator for fields in a CSV file. BigQuery converts the string to <code class=\"highlighter-rouge\">ISO-8859-1</code> encoding, and then uses the first byte of the encoded string to split the data in its raw, binary state. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":null,"optional":true,"default":"nil","nullable":true},{"name":"max_bad_records","types":["Integer"],"description":"The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value, an invalid error is returned in the job result. The default value is <code class=\"highlighter-rouge\">0</code>, which requires that all records are valid.","optional":true,"default":"nil","nullable":true},{"name":"quote","types":["String"],"description":"The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the data in its raw, binary state. The default value is a double-quote <code>\"</code>. If your data does not contain quoted sections, set the property value to an empty string. If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.","optional":true,"default":"nil","nullable":true},{"name":"skip_leading","types":["Integer"],"description":"The number of rows at the top of a CSV file that BigQuery will skip when loading the data. The default value is <code class=\"highlighter-rouge\">0</code>. This property is useful if you have header rows in the file that should be skipped.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Gcloud::Bigquery::LoadJob"],"description":null}]},{"metadata":{"name":"insert","description":"<p>Inserts data into the table for near-immediate querying, without the need to complete a #load operation before the data can appear in query results.</p>","source":"lib/gcloud/bigquery/table.rb#L792","resources":[{"title":"Streaming Data Into BigQuery","link":"https://cloud.google.com/bigquery/streaming-data-into-bigquery"}],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ntable.insert rows"}]},"params":[{"name":"rows","types":["Hash","Array<Hash>"],"description":"A hash object or array of hash objects containing the data.","optional":false,"nullable":false},{"name":"skip_invalid","types":["Boolean"],"description":"Insert all valid rows of a request, even if invalid rows exist. The default value is <code class=\"highlighter-rouge\">false</code>, which causes the entire request to fail if any invalid rows exist.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Accept rows that contain values that do not match the schema. The unknown values are ignored. Default is false, which treats unknown values as errors.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Gcloud::Bigquery::InsertResponse"],"description":null}]},{"metadata":{"name":"delete","description":"<p>Permanently deletes the table.</p>","source":"lib/gcloud/bigquery/table.rb#L821","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.delete"}]},"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"Returns <code class=\"highlighter-rouge\">true</code> if the table was deleted."}]},{"metadata":{"name":"reload!","description":"<p>Reloads the table with current data from the BigQuery service.</p>","source":"lib/gcloud/bigquery/table.rb#L836","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"ensure_connection!","description":"<p>Raise an error unless an active connection is available.</p>","source":"lib/gcloud/bigquery/table.rb#L861","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"patch_gapi!","description":"","source":"lib/gcloud/bigquery/table.rb#L865","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"class_for","description":"","source":"lib/gcloud/bigquery/table.rb#L875","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"load_storage","description":"","source":"lib/gcloud/bigquery/table.rb#L880","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"load_local","description":"","source":"lib/gcloud/bigquery/table.rb#L892","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"load_resumable","description":"","source":"lib/gcloud/bigquery/table.rb#L900","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"load_multipart","description":"","source":"lib/gcloud/bigquery/table.rb#L910","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"storage_url?","description":"","source":"lib/gcloud/bigquery/table.rb#L925","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":null}]},{"metadata":{"name":"local_file?","description":"","source":"lib/gcloud/bigquery/table.rb#L931","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":null}]},{"metadata":{"name":"verify_chunk_size!","description":"<p>Determines if a chunk_size is valid.</p>","source":"lib/gcloud/bigquery/table.rb#L939","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"ensure_full_data!","description":"<p>Load the complete representation of the table if it has been only partially loaded by a request to the API list method.</p>","source":"lib/gcloud/bigquery/table.rb#L952","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"reload_gapi!","description":"","source":"lib/gcloud/bigquery/table.rb#L956","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]},{"metadata":{"name":"data_complete?","description":"","source":"lib/gcloud/bigquery/table.rb#L966","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":null}]},{"metadata":{"name":"get_table_ref","description":"","source":"lib/gcloud/bigquery/table.rb#L972","resources":[],"examples":[]},"params":[],"exceptions":[],"returns":[]}]}