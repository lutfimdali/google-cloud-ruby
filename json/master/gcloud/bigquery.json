{"id":"bigquery","metadata":{"name":"Bigquery","description":"<h1 id=\"google-cloud-bigquery\">Google Cloud BigQuery</h1>\n\n<p>Google Cloud BigQuery enables super-fast, SQL-like queries against massive\ndatasets, using the processing power of Google’s infrastructure. To learn\nmore, read <a href=\"https://cloud.google.com/bigquery/what-is-bigquery\">What is\nBigQuery?</a>.</p>\n\n<p>Gcloud’s goal is to provide an API that is familiar and comfortable to\nRubyists. Authentication is handled by Gcloud#bigquery. You can provide\nthe project and credential information to connect to the BigQuery service,\nor if you are running on Google Compute Engine this configuration is taken\ncare of for you. You can read more about the options for connecting in the\n<a href=\"../AUTHENTICATION\">Authentication Guide</a>.</p>\n\n<p>To help you get started quickly, the first few examples below use a public\ndataset provided by Google. As soon as you have <a href=\"https://cloud.google.com/bigquery/sign-up\">signed\nup</a> to use BigQuery, and provided\nthat you stay in the free tier for queries, you should be able to run these\nfirst examples without the need to set up billing or to load data (although\nwe’ll show you how to do that too.)</p>\n\n<h2 id=\"listing-datasets-and-tables\">Listing Datasets and Tables</h2>\n\n<p>A BigQuery project holds datasets, which in turn hold tables. Assuming that\nyou have not yet created datasets or tables in your own project, let’s\nconnect to Google’s <code class=\"highlighter-rouge\">publicdata</code> project, and see what you find.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span> <span class=\"s2\">\"publicdata\"</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n\n<span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">datasets</span><span class=\"p\">.</span><span class=\"nf\">count</span> <span class=\"c1\">#=&gt; 1</span>\n<span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">datasets</span><span class=\"p\">.</span><span class=\"nf\">first</span><span class=\"p\">.</span><span class=\"nf\">dataset_id</span> <span class=\"c1\">#=&gt; \"samples\"</span>\n\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">datasets</span><span class=\"p\">.</span><span class=\"nf\">first</span>\n<span class=\"n\">tables</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">tables</span>\n\n<span class=\"n\">tables</span><span class=\"p\">.</span><span class=\"nf\">count</span> <span class=\"c1\">#=&gt; 7</span>\n<span class=\"n\">tables</span><span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"o\">&amp;</span><span class=\"ss\">:table_id</span> <span class=\"c1\">#=&gt; [..., \"shakespeare\", \"trigrams\", \"wikipedia\"]</span>\n</code></pre>\n</div>\n\n<p>In addition listing all datasets and tables in the project, you can also\nretrieve individual datasets and tables by ID. Let’s look at the structure\nof the <code class=\"highlighter-rouge\">shakespeare</code> table, which contains an entry for every word in every\nplay written by Shakespeare.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span> <span class=\"s2\">\"publicdata\"</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">dataset</span> <span class=\"s2\">\"samples\"</span>\n<span class=\"n\">table</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">table</span> <span class=\"s2\">\"shakespeare\"</span>\n\n<span class=\"n\">table</span><span class=\"p\">.</span><span class=\"nf\">headers</span> <span class=\"c1\">#=&gt; [\"word\", \"word_count\", \"corpus\", \"corpus_date\"]</span>\n<span class=\"n\">table</span><span class=\"p\">.</span><span class=\"nf\">rows_count</span> <span class=\"c1\">#=&gt; 164656</span>\n</code></pre>\n</div>\n\n<p>Now that you know the column names for the Shakespeare table, you can write\nand run a query.</p>\n\n<h2 id=\"running-queries\">Running queries</h2>\n\n<p>BigQuery offers both synchronous and asynchronous methods, as explained in\n<a href=\"https://cloud.google.com/bigquery/querying-data\">Querying Data</a>.</p>\n\n<h3 id=\"synchronous-queries\">Synchronous queries</h3>\n\n<p>Let’s start with the simpler synchronous approach. Notice that this time you\nare connecting using your own default project. This is necessary for running\na query, since queries need to be able to create tables to hold results.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n\n<span class=\"n\">sql</span> <span class=\"o\">=</span> <span class=\"s2\">\"SELECT TOP(word, 50) as word, COUNT(*) as count \"</span> <span class=\"o\">+</span>\n      <span class=\"s2\">\"FROM publicdata:samples.shakespeare\"</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">query</span> <span class=\"n\">sql</span>\n\n<span class=\"n\">data</span><span class=\"p\">.</span><span class=\"nf\">count</span> <span class=\"c1\">#=&gt; 50</span>\n<span class=\"n\">data</span><span class=\"p\">.</span><span class=\"nf\">next?</span> <span class=\"c1\">#=&gt; false</span>\n<span class=\"n\">data</span><span class=\"p\">.</span><span class=\"nf\">first</span> <span class=\"c1\">#=&gt; {\"word\"=&gt;\"you\", \"count\"=&gt;42}</span>\n</code></pre>\n</div>\n\n<p>The <code class=\"highlighter-rouge\">TOP</code> function shown above is just one of a variety of functions\noffered by BigQuery. See the <a href=\"https://cloud.google.com/bigquery/query-reference\">Query\nReference</a> for a full\nlisting.</p>\n\n<h3 id=\"asynchronous-queries\">Asynchronous queries</h3>\n\n<p>Because you probably should not block for most BigQuery operations,\nincluding querying as well as importing, exporting, and copying data, the\nBigQuery API enables you to manage longer-running jobs. In the asynchronous\napproach to running a query, an instance of Gcloud::Bigquery::QueryJob is\nreturned, rather than an instance of Gcloud::Bigquery::QueryData.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n\n<span class=\"n\">sql</span> <span class=\"o\">=</span> <span class=\"s2\">\"SELECT TOP(word, 50) as word, COUNT(*) as count \"</span> <span class=\"o\">+</span>\n      <span class=\"s2\">\"FROM publicdata:samples.shakespeare\"</span>\n<span class=\"n\">job</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">query_job</span> <span class=\"n\">sql</span>\n\n<span class=\"n\">job</span><span class=\"p\">.</span><span class=\"nf\">wait_until_done!</span>\n<span class=\"k\">if</span> <span class=\"o\">!</span><span class=\"n\">job</span><span class=\"p\">.</span><span class=\"nf\">failed?</span>\n  <span class=\"n\">job</span><span class=\"p\">.</span><span class=\"nf\">query_results</span><span class=\"p\">.</span><span class=\"nf\">each</span> <span class=\"k\">do</span> <span class=\"o\">|</span><span class=\"n\">row</span><span class=\"o\">|</span>\n    <span class=\"nb\">puts</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s2\">\"word\"</span><span class=\"p\">]</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre>\n</div>\n\n<p>Once you have determined that the job is done and has not failed, you can\nobtain an instance of Gcloud::Bigquery::QueryData by calling\nGcloud::Bigquery::QueryJob#query_results. The query results for both of\nthe above examples are stored in temporary tables with a lifetime of about\n24 hours. See the final example below for a demonstration of how to store\nquery results in a permanent table.</p>\n\n<h2 id=\"creating-datasets-and-tables\">Creating Datasets and Tables</h2>\n\n<p>The first thing you need to do in a new BigQuery project is to create a\nGcloud::Bigquery::Dataset. Datasets hold tables and control access to them.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud/bigquery\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">create_dataset</span> <span class=\"s2\">\"my_dataset\"</span>\n</code></pre>\n</div>\n\n<p>Now that you have a dataset, you can use it to create a table. Every table\nis defined by a schema that may contain nested and repeated fields. The\nexample below shows a schema with a repeated record field named\n<code class=\"highlighter-rouge\">cities_lived</code>. (For more information about nested and repeated fields, see\n<a href=\"https://cloud.google.com/bigquery/preparing-data-for-bigquery\">Preparing Data for\nBigQuery</a>.)</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">dataset</span> <span class=\"s2\">\"my_dataset\"</span>\n\n<span class=\"n\">table</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">create_table</span> <span class=\"s2\">\"people\"</span> <span class=\"k\">do</span> <span class=\"o\">|</span><span class=\"n\">schema</span><span class=\"o\">|</span>\n  <span class=\"n\">schema</span><span class=\"p\">.</span><span class=\"nf\">string</span> <span class=\"s2\">\"first_name\"</span><span class=\"p\">,</span> <span class=\"ss\">mode: :required</span>\n  <span class=\"n\">schema</span><span class=\"p\">.</span><span class=\"nf\">record</span> <span class=\"s2\">\"cities_lived\"</span><span class=\"p\">,</span> <span class=\"ss\">mode: :repeated</span> <span class=\"k\">do</span> <span class=\"o\">|</span><span class=\"n\">nested_schema</span><span class=\"o\">|</span>\n    <span class=\"n\">nested_schema</span><span class=\"p\">.</span><span class=\"nf\">string</span> <span class=\"s2\">\"place\"</span><span class=\"p\">,</span> <span class=\"ss\">mode: :required</span>\n    <span class=\"n\">nested_schema</span><span class=\"p\">.</span><span class=\"nf\">integer</span> <span class=\"s2\">\"number_of_years\"</span><span class=\"p\">,</span> <span class=\"ss\">mode: :required</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span>\n</code></pre>\n</div>\n\n<p>Because of the repeated field in this schema, we cannot use the CSV format\nto load data into the table.</p>\n\n<h2 id=\"loading-records\">Loading records</h2>\n\n<p>In addition to CSV, data can be imported from files that are formatted as\n<a href=\"http://jsonlines.org/\">Newline-delimited JSON</a> or\n<a href=\"http://avro.apache.org/\">Avro</a>, or from a Google Cloud Datastore backup. It\ncan also be “streamed” into BigQuery.</p>\n\n<p>To follow along with these examples, you will need to set up billing on the\n<a href=\"https://console.developers.google.com\">Google Developers Console</a>.</p>\n\n<h3 id=\"streaming-records\">Streaming records</h3>\n\n<p>For situations in which you want new data to be available for querying as\nsoon as possible, inserting individual records directly from your Ruby\napplication is a great approach.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">dataset</span> <span class=\"s2\">\"my_dataset\"</span>\n<span class=\"n\">table</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">table</span> <span class=\"s2\">\"people\"</span>\n\n<span class=\"n\">rows</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"p\">{</span>\n        <span class=\"s2\">\"first_name\"</span> <span class=\"o\">=&gt;</span> <span class=\"s2\">\"Anna\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"cities_lived\"</span> <span class=\"o\">=&gt;</span> <span class=\"p\">[</span>\n            <span class=\"p\">{</span>\n                <span class=\"s2\">\"place\"</span> <span class=\"o\">=&gt;</span> <span class=\"s2\">\"Stockholm\"</span><span class=\"p\">,</span>\n                <span class=\"s2\">\"number_of_years\"</span> <span class=\"o\">=&gt;</span> <span class=\"mi\">2</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">]</span>\n    <span class=\"p\">},</span>\n    <span class=\"p\">{</span>\n        <span class=\"s2\">\"first_name\"</span> <span class=\"o\">=&gt;</span> <span class=\"s2\">\"Bob\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"cities_lived\"</span> <span class=\"o\">=&gt;</span> <span class=\"p\">[</span>\n            <span class=\"p\">{</span>\n                <span class=\"s2\">\"place\"</span> <span class=\"o\">=&gt;</span> <span class=\"s2\">\"Seattle\"</span><span class=\"p\">,</span>\n                <span class=\"s2\">\"number_of_years\"</span> <span class=\"o\">=&gt;</span> <span class=\"mi\">5</span>\n            <span class=\"p\">},</span>\n            <span class=\"p\">{</span>\n                <span class=\"s2\">\"place\"</span> <span class=\"o\">=&gt;</span> <span class=\"s2\">\"Austin\"</span><span class=\"p\">,</span>\n                <span class=\"s2\">\"number_of_years\"</span> <span class=\"o\">=&gt;</span> <span class=\"mi\">6</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">]</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">]</span>\n<span class=\"n\">table</span><span class=\"p\">.</span><span class=\"nf\">insert</span> <span class=\"n\">rows</span>\n</code></pre>\n</div>\n\n<p>There are some trade-offs involved with streaming, so be sure to read the\ndiscussion of data consistency in <a href=\"https://cloud.google.com/bigquery/streaming-data-into-bigquery\">Streaming Data Into\nBigQuery</a>.</p>\n\n<h3 id=\"uploading-a-file\">Uploading a file</h3>\n\n<p>To follow along with this example, please download the\n<a href=\"http://www.ssa.gov/OACT/babynames/names.zip\">names.zip</a> archive from the\nU.S. Social Security Administration. Inside the archive you will find over\n100 files containing baby name records since the year 1880. A PDF file also\ncontained in the archive specifies the schema used below.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">dataset</span> <span class=\"s2\">\"my_dataset\"</span>\n<span class=\"n\">table</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">create_table</span> <span class=\"s2\">\"baby_names\"</span> <span class=\"k\">do</span> <span class=\"o\">|</span><span class=\"n\">schema</span><span class=\"o\">|</span>\n  <span class=\"n\">schema</span><span class=\"p\">.</span><span class=\"nf\">string</span> <span class=\"s2\">\"name\"</span><span class=\"p\">,</span> <span class=\"ss\">mode: :required</span>\n  <span class=\"n\">schema</span><span class=\"p\">.</span><span class=\"nf\">string</span> <span class=\"s2\">\"sex\"</span><span class=\"p\">,</span> <span class=\"ss\">mode: :required</span>\n  <span class=\"n\">schema</span><span class=\"p\">.</span><span class=\"nf\">integer</span> <span class=\"s2\">\"number\"</span><span class=\"p\">,</span> <span class=\"ss\">mode: :required</span>\n<span class=\"k\">end</span>\n\n<span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"no\">File</span><span class=\"p\">.</span><span class=\"nf\">open</span> <span class=\"s2\">\"names/yob2014.txt\"</span>\n<span class=\"n\">load_job</span> <span class=\"o\">=</span> <span class=\"n\">table</span><span class=\"p\">.</span><span class=\"nf\">load</span> <span class=\"n\">file</span><span class=\"p\">,</span> <span class=\"ss\">format: </span><span class=\"s2\">\"csv\"</span>\n</code></pre>\n</div>\n\n<p>Because the names data, although formatted as CSV, is distributed in files\nwith a <code class=\"highlighter-rouge\">.txt</code> extension, this example explicitly passes the <code class=\"highlighter-rouge\">format</code> option\nin order to demonstrate how to handle such situations. Because CSV is the\ndefault format for load operations, the option is not actually necessary.\nFor JSON saved with a <code class=\"highlighter-rouge\">.txt</code> extension, however, it would be.</p>\n\n<h3 id=\"a-note-about-large-uploads\">A note about large uploads</h3>\n\n<p>You may encounter a Broken pipe (Errno::EPIPE) error when attempting to\nupload large files. To avoid this problem, add the\n<a href=\"https://rubygems.org/gems/httpclient\">httpclient</a> gem to your project, and\nthe line (or lines) of configuration shown below. These lines must execute\nafter you require gcloud but before you make your first gcloud connection.\nThe first statement configures <a href=\"https://rubygems.org/gems/faraday\">Faraday</a>\nto use httpclient. The second statement, which should only be added if you\nare using a version of Faraday at or above 0.9.2, is a workaround for <a href=\"https://github.com/GoogleCloudPlatform/gcloud-ruby/issues/367\">this\ngzip issue</a>.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"c1\"># Use httpclient to avoid broken pipe errors with large uploads</span>\n<span class=\"no\">Faraday</span><span class=\"p\">.</span><span class=\"nf\">default_adapter</span> <span class=\"o\">=</span> <span class=\"ss\">:httpclient</span>\n\n<span class=\"c1\"># Only add the following statement if using Faraday &gt;= 0.9.2</span>\n<span class=\"c1\"># Override gzip middleware with no-op for httpclient</span>\n<span class=\"no\">Faraday</span><span class=\"o\">::</span><span class=\"no\">Response</span><span class=\"p\">.</span><span class=\"nf\">register_middleware</span> <span class=\"ss\">:gzip</span> <span class=\"o\">=&gt;</span>\n                                        <span class=\"no\">Faraday</span><span class=\"o\">::</span><span class=\"no\">Response</span><span class=\"o\">::</span><span class=\"no\">Middleware</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n</code></pre>\n</div>\n\n<h2 id=\"exporting-query-results-to-google-cloud-storage\">Exporting query results to Google Cloud Storage</h2>\n\n<p>The example below shows how to pass the <code class=\"highlighter-rouge\">table</code> option with a query in order\nto store results in a permanent table. It also shows how to export the\nresult data to a Google Cloud Storage file. In order to follow along, you\nwill need to enable the Google Cloud Storage API in addition to setting up\nbilling.</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"ruby\"><code><span class=\"nb\">require</span> <span class=\"s2\">\"gcloud\"</span>\n\n<span class=\"n\">gcloud</span> <span class=\"o\">=</span> <span class=\"no\">Gcloud</span><span class=\"p\">.</span><span class=\"nf\">new</span>\n<span class=\"n\">bigquery</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">bigquery</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">bigquery</span><span class=\"p\">.</span><span class=\"nf\">dataset</span> <span class=\"s2\">\"my_dataset\"</span>\n<span class=\"n\">source_table</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">table</span> <span class=\"s2\">\"baby_names\"</span>\n<span class=\"n\">result_table</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">create_table</span> <span class=\"s2\">\"baby_names_results\"</span>\n\n<span class=\"n\">sql</span> <span class=\"o\">=</span> <span class=\"s2\">\"SELECT name, number as count \"</span> <span class=\"o\">+</span>\n      <span class=\"s2\">\"FROM baby_names \"</span> <span class=\"o\">+</span>\n      <span class=\"s2\">\"WHERE name CONTAINS 'Sam' \"</span> <span class=\"o\">+</span>\n      <span class=\"s2\">\"ORDER BY count DESC\"</span>\n<span class=\"n\">query_job</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"p\">.</span><span class=\"nf\">query_job</span> <span class=\"n\">sql</span><span class=\"p\">,</span> <span class=\"ss\">table: </span><span class=\"n\">result_table</span>\n\n<span class=\"n\">query_job</span><span class=\"p\">.</span><span class=\"nf\">wait_until_done!</span>\n\n<span class=\"k\">if</span> <span class=\"o\">!</span><span class=\"n\">query_job</span><span class=\"p\">.</span><span class=\"nf\">failed?</span>\n\n  <span class=\"n\">storage</span> <span class=\"o\">=</span> <span class=\"n\">gcloud</span><span class=\"p\">.</span><span class=\"nf\">storage</span>\n  <span class=\"n\">bucket_id</span> <span class=\"o\">=</span> <span class=\"s2\">\"bigquery-exports-</span><span class=\"si\">#{</span><span class=\"no\">SecureRandom</span><span class=\"p\">.</span><span class=\"nf\">uuid</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n  <span class=\"n\">bucket</span> <span class=\"o\">=</span> <span class=\"n\">storage</span><span class=\"p\">.</span><span class=\"nf\">create_bucket</span> <span class=\"n\">bucket_id</span>\n  <span class=\"n\">extract_url</span> <span class=\"o\">=</span> <span class=\"s2\">\"gs://</span><span class=\"si\">#{</span><span class=\"n\">bucket</span><span class=\"p\">.</span><span class=\"nf\">id</span><span class=\"si\">}</span><span class=\"s2\">/baby-names-sam.csv\"</span>\n\n  <span class=\"n\">extract_job</span> <span class=\"o\">=</span> <span class=\"n\">result_table</span><span class=\"p\">.</span><span class=\"nf\">extract</span> <span class=\"n\">extract_url</span>\n\n  <span class=\"n\">extract_job</span><span class=\"p\">.</span><span class=\"nf\">wait_until_done!</span>\n\n  <span class=\"c1\"># Download to local filesystem</span>\n  <span class=\"n\">bucket</span><span class=\"p\">.</span><span class=\"nf\">files</span><span class=\"p\">.</span><span class=\"nf\">first</span><span class=\"p\">.</span><span class=\"nf\">download</span> <span class=\"s2\">\"baby-names-sam.csv\"</span>\n\n<span class=\"k\">end</span>\n</code></pre>\n</div>\n\n<p>If a table you wish to export contains a large amount of data, you can pass\na wildcard URI to export to multiple files (for sharding), or an array of\nURIs (for partitioning), or both. See <a href=\"https://cloud.google.com/bigquery/exporting-data-from-bigquery\">Exporting Data From\nBigQuery</a>\nfor details.</p>","source":"lib/gcloud/bigquery.rb#L384","resources":[],"examples":[]},"methods":[]}