{"id":"gcloud/bigquery/table","name":"Table","title":["Gcloud","Bigquery","Table"],"description":"<h1 id=\"table\">Table</h1>\n\n<p>A named resource representing a BigQuery table that holds zero or more\nrecords. Every table is defined by a schema that may contain nested and\nrepeated fields.</p>","source":"lib/gcloud/bigquery/table.rb#L66","resources":[{"title":"Preparing Data for BigQuery","link":"https://cloud.google.com/bigquery/preparing-data-for-bigquery"}],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\n\ntable = dataset.create_table \"my_table\" do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend\n\nrow = {\n  \"first_name\" => \"Alice\",\n  \"cities_lived\" => [\n    {\n      \"place\" => \"Seattle\",\n      \"number_of_years\" => 5\n    },\n    {\n      \"place\" => \"Stockholm\",\n      \"number_of_years\" => 6\n    }\n  ]\n}\ntable.insert row"}],"methods":[{"id":"table_id-instance","type":"instance","name":"table_id","title":["Gcloud","Bigquery","Table#table_id"],"description":"<p>A unique ID for this table.\nThe ID must contain only letters (a-z, A-Z), numbers (0-9),\nor underscores (_). The maximum length is 1,024 characters.</p>","source":"lib/gcloud/bigquery/table.rb#L89","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"dataset_id-instance","type":"instance","name":"dataset_id","title":["Gcloud","Bigquery","Table#dataset_id"],"description":"<p>The ID of the <code>Dataset</code> containing this table.</p>","source":"lib/gcloud/bigquery/table.rb#L98","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"project_id-instance","type":"instance","name":"project_id","title":["Gcloud","Bigquery","Table#project_id"],"description":"<p>The ID of the <code>Project</code> containing this table.</p>","source":"lib/gcloud/bigquery/table.rb#L107","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"id-instance","type":"instance","name":"id","title":["Gcloud","Bigquery","Table#id"],"description":"<p>The combined Project ID, Dataset ID, and Table ID for this table, in the\nformat specified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query\nReference</a>:\n<code>project_name:datasetId.tableId</code>. To use this value in queries see\n<a data-custom-type=\"gcloud/bigquery/table\" data-method=\"query_id-instance\">#query_id</a>.</p>","source":"lib/gcloud/bigquery/table.rb#L130","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"query_id-instance","type":"instance","name":"query_id","title":["Gcloud","Bigquery","Table#query_id"],"description":"<p>The value returned by <a data-custom-type=\"gcloud/bigquery/table\" data-method=\"id-instance\">#id</a>, wrapped in square brackets if the Project\nID contains dashes, as specified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query\nReference</a>.\nUseful in queries.</p>","source":"lib/gcloud/bigquery/table.rb#L152","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ndata = bigquery.query \"SELECT name FROM #{table.query_id}\""}],"params":[],"exceptions":[],"returns":[]},{"id":"name-instance","type":"instance","name":"name","title":["Gcloud","Bigquery","Table#name"],"description":"<p>The name of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L161","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"name=-instance","type":"instance","name":"name=","title":["Gcloud","Bigquery","Table#name="],"description":"<p>Updates the name of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L170","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"etag-instance","type":"instance","name":"etag","title":["Gcloud","Bigquery","Table#etag"],"description":"<p>A string hash of the dataset.</p>","source":"lib/gcloud/bigquery/table.rb#L179","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"api_url-instance","type":"instance","name":"api_url","title":["Gcloud","Bigquery","Table#api_url"],"description":"<p>A URL that can be used to access the dataset using the REST API.</p>","source":"lib/gcloud/bigquery/table.rb#L189","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"description-instance","type":"instance","name":"description","title":["Gcloud","Bigquery","Table#description"],"description":"<p>The description of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L199","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"description=-instance","type":"instance","name":"description=","title":["Gcloud","Bigquery","Table#description="],"description":"<p>Updates the description of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L209","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"bytes_count-instance","type":"instance","name":"bytes_count","title":["Gcloud","Bigquery","Table#bytes_count"],"description":"<p>The number of bytes in the table.</p>","source":"lib/gcloud/bigquery/table.rb#L218","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"rows_count-instance","type":"instance","name":"rows_count","title":["Gcloud","Bigquery","Table#rows_count"],"description":"<p>The number of rows in the table.</p>","source":"lib/gcloud/bigquery/table.rb#L228","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"created_at-instance","type":"instance","name":"created_at","title":["Gcloud","Bigquery","Table#created_at"],"description":"<p>The time when this table was created.</p>","source":"lib/gcloud/bigquery/table.rb#L238","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"expires_at-instance","type":"instance","name":"expires_at","title":["Gcloud","Bigquery","Table#expires_at"],"description":"<p>The time when this table expires.\nIf not present, the table will persist indefinitely.\nExpired tables will be deleted and their storage reclaimed.</p>","source":"lib/gcloud/bigquery/table.rb#L250","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"modified_at-instance","type":"instance","name":"modified_at","title":["Gcloud","Bigquery","Table#modified_at"],"description":"<p>The date when this table was last modified.</p>","source":"lib/gcloud/bigquery/table.rb#L261","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"table?-instance","type":"instance","name":"table?","title":["Gcloud","Bigquery","Table#table?"],"description":"<p>Checks if the table’s type is “TABLE”.</p>","source":"lib/gcloud/bigquery/table.rb#L271","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"view?-instance","type":"instance","name":"view?","title":["Gcloud","Bigquery","Table#view?"],"description":"<p>Checks if the table’s type is “VIEW”.</p>","source":"lib/gcloud/bigquery/table.rb#L280","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":""}]},{"id":"location-instance","type":"instance","name":"location","title":["Gcloud","Bigquery","Table#location"],"description":"<p>The geographic location where the table should reside. Possible\nvalues include EU and US. The default value is US.</p>","source":"lib/gcloud/bigquery/table.rb#L290","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"schema-instance","type":"instance","name":"schema","title":["Gcloud","Bigquery","Table#schema"],"description":"<p>Returns the table’s schema as hash containing the keys and values\nreturned by the Google Cloud BigQuery <a href=\"https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\">Rest API\n</a>.\nThis method can also be used to set, replace, or add to the schema by\npassing a block. See <a data-custom-type=\"gcloud/bigquery/table/schema\">Table::Schema</a> for available methods. To set the\nschema by passing a hash instead, use <a data-custom-type=\"gcloud/bigquery/table\" data-method=\"schema=-instance\">#schema=</a>.</p>","source":"lib/gcloud/bigquery/table.rb#L329","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.create_table \"my_table\"\n\ntable.schema do |schema|\n  schema.string \"first_name\", mode: :required\n  schema.record \"cities_lived\", mode: :repeated do |nested_schema|\n    nested_schema.string \"place\", mode: :required\n    nested_schema.integer \"number_of_years\", mode: :required\n  end\nend"}],"params":[{"name":"replace","types":["Boolean"],"description":"Whether to replace the existing schema with the\nnew schema. If <code>true</code>, the fields will replace the existing schema. If\n<code>false</code>, the fields will be added to the existing schema. When a table\nalready contains data, schema changes must be additive. Thus, the\ndefault value is <code>false</code>.","optional":true,"default":"false","nullable":false},{"name":"yield","types":["block"],"description":"a block for setting the schema","optional":true,"nullable":false},{"name":"yield.schema","types":["Table::Schema"],"description":"the object accepting the schema","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"schema=-instance","type":"instance","name":"schema=","title":["Gcloud","Bigquery","Table#schema="],"description":"<p>Updates the schema of the table.\nTo update the schema using a block instead, use #schema.</p>","source":"lib/gcloud/bigquery/table.rb#L376","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.create_table \"my_table\"\n\nschema = {\n  \"fields\" => [\n    {\n      \"name\" => \"first_name\",\n      \"type\" => \"STRING\",\n      \"mode\" => \"REQUIRED\"\n    },\n    {\n      \"name\" => \"age\",\n      \"type\" => \"INTEGER\",\n      \"mode\" => \"REQUIRED\"\n    }\n  ]\n}\ntable.schema = schema"}],"params":[{"name":"new_schema","types":["Hash"],"description":"A hash containing keys and values as specified\nby the Google Cloud BigQuery <a href=\"https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\">Rest API\n</a>\n.","optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"fields-instance","type":"instance","name":"fields","title":["Gcloud","Bigquery","Table#fields"],"description":"<p>The fields of the table.</p>","source":"lib/gcloud/bigquery/table.rb#L385","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"headers-instance","type":"instance","name":"headers","title":["Gcloud","Bigquery","Table#headers"],"description":"<p>The names of the columns in the table.</p>","source":"lib/gcloud/bigquery/table.rb#L397","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"data-instance","type":"instance","name":"data","title":["Gcloud","Bigquery","Table#data"],"description":"<p>Retrieves data from the table.</p>","source":"lib/gcloud/bigquery/table.rb#L428","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ndata = table.data\ndata.each do |row|\n  puts row[\"first_name\"]\nend\nmore_data = table.data token: data.token"}],"params":[{"name":"token","types":["String"],"description":"Page token, returned by a previous call,\nidentifying the result set.","optional":true,"default":"nil","nullable":true},{"name":"max","types":["Integer"],"description":"Maximum number of results to return.","optional":true,"default":"nil","nullable":true},{"name":"start","types":["Integer"],"description":"Zero-based index of the starting row to read.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"gcloud/bigquery/data\">Gcloud::Bigquery::Data</a>"],"description":""}]},{"id":"copy-instance","type":"instance","name":"copy","title":["Gcloud","Bigquery","Table#copy"],"description":"<p>Copies the data from the table to another table.\nThe destination table argument can also be a string identifier as\nspecified by the <a href=\"https://cloud.google.com/bigquery/query-reference#from\">Query\nReference</a>:\n<code>project_name:datasetId.tableId</code>. This is useful for referencing tables\nin other projects and datasets.</p>","source":"lib/gcloud/bigquery/table.rb#L492","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\ndestination_table = dataset.table \"my_destination_table\"\n\ncopy_job = table.copy destination_table"},{"caption":"<p>Passing a string identifier for the destination table:</p>","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ncopy_job = table.copy \"other-project:other_dataset.other_table\""}],"params":[{"name":"destination_table","types":["Table","String"],"description":"The destination for the copied\ndata.","optional":false,"nullable":false},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe destination table. The default value is <code>empty</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the destination table already\ncontains data.</li>\n</ul>","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"gcloud/bigquery/copyjob\">Gcloud::Bigquery::CopyJob</a>"],"description":""}]},{"id":"extract-instance","type":"instance","name":"extract","title":["Gcloud","Bigquery","Table#extract"],"description":"<p>Extract the data from the table to a Google Cloud Storage file.</p>","source":"lib/gcloud/bigquery/table.rb#L584","resources":[{"title":"Exporting Data From BigQuery","link":"https://cloud.google.com/bigquery/exporting-data-from-bigquery"}],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nextract_job = table.extract \"gs://my-bucket/file-name.json\",\n                            format: \"json\""}],"params":[{"name":"extract_url","types":["Gcloud::Storage::File","String","Array<String>"],"description":"The\nGoogle Storage file or file URI pattern(s) to which BigQuery should\nextract the table data.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"compression","types":["String"],"description":"The compression type to use for exported\nfiles. Possible values include <code>GZIP</code> and <code>NONE</code>. The default value is\n<code>NONE</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Delimiter to use between fields in the\nexported data. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"header","types":["Boolean"],"description":"Whether to print out a header row in the\nresults. Default is <code>true</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"gcloud/bigquery/extractjob\">Gcloud::Bigquery::ExtractJob</a>"],"description":""}]},{"id":"load-instance","type":"instance","name":"load","title":["Gcloud","Bigquery","Table#load"],"description":"<p>Loads data into the table. You can pass a gcloud storage file path or\na gcloud storage file instance. Or, you can upload a file directly.\nSee <a href=\"https://cloud.google.com/bigquery/loading-data-post-request#multipart\">Loading Data with a POST Request</a>.</p>\n\n<p>A <code>chunk_size</code> value can be provided in the options to be used in\nresumable uploads. This value is the number of bytes per chunk and must\nbe divisible by 256KB. If it is not divisible by 256KB then it will be\nlowered to the nearest acceptable value.</p>\n\n<h3 id=\"a-note-about-large-direct-uploads\">A note about large direct uploads</h3>\n\n<p>You may encounter a Broken pipe (Errno::EPIPE) error when attempting to\nupload large files. To avoid this problem, add the\n<a href=\"https://rubygems.org/gems/httpclient\">httpclient</a> gem to your project,\nand the line (or lines) of configuration shown below. These lines must\nexecute after you require gcloud but before you make your first gcloud\nconnection. The first statement configures\n<a href=\"https://rubygems.org/gems/faraday\">Faraday</a> to use httpclient. The\nsecond statement, which should only be added if you are using a version\nof Faraday at or above 0.9.2, is a workaround for <a href=\"https://github.com/GoogleCloudPlatform/gcloud-ruby/issues/367\">this gzip\nissue</a>.</p>","source":"lib/gcloud/bigquery/table.rb#L757","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nload_job = table.load \"gs://my-bucket/file-name.csv\""},{"caption":"<p>Pass a gcloud storage file instance:</p>","code":"require \"gcloud\"\nrequire \"gcloud/storage\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nstorage = gcloud.storage\nbucket = storage.bucket \"my-bucket\"\nfile = bucket.file \"file-name.csv\"\nload_job = table.load file"},{"caption":"<p>Upload a file directly:</p>","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nfile = File.open \"my_data.csv\"\nload_job = table.load file"},{"caption":"","code":"require \"gcloud\"\n\n# Use httpclient to avoid broken pipe errors with large uploads\nFaraday.default_adapter = :httpclient\n\n# Only add the following statement if using Faraday >= 0.9.2\n# Override gzip middleware with no-op for httpclient\nFaraday::Response.register_middleware :gzip =>\n                                        Faraday::Response::Middleware\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery"}],"params":[{"name":"file","types":["File","Gcloud::Storage::File","String"],"description":"A file or the URI of a\nGoogle Cloud Storage file containing data to load into the table.","optional":false,"nullable":false},{"name":"format","types":["String"],"description":"The exported file format. The default value is\n<code>csv</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>csv</code> - CSV</li>\n  <li><code>json</code> - <a href=\"http://jsonlines.org/\">Newline-delimited JSON</a></li>\n  <li><code>avro</code> - <a href=\"http://avro.apache.org/\">Avro</a></li>\n  <li><code>datastore_backup</code> - Cloud Datastore backup</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"create","types":["String"],"description":"Specifies whether the job is allowed to create\nnew tables.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>needed</code> - Create the table if it does not exist.</li>\n  <li><code>never</code> - The table must already exist. A ‘notFound’ error is\nraised if the table does not exist.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"write","types":["String"],"description":"Specifies how to handle data already present in\nthe table. The default value is <code>empty</code>.</p>\n\n<p>The following values are supported:</p>\n\n<ul>\n  <li><code>truncate</code> - BigQuery overwrites the table data.</li>\n  <li><code>append</code> - BigQuery appends the data to the table.</li>\n  <li><code>empty</code> - An error will be returned if the table already contains\ndata.</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"projection_fields","types":["Array<String>"],"description":"If the <code>format</code> option is set\nto <code>datastore_backup</code>, indicates which entity properties to load from\na Cloud Datastore backup. Property names are case sensitive and must\nbe top-level properties. If not set, BigQuery loads all properties. If\nany named property isn’t found in the Cloud Datastore backup, an\ninvalid error is returned.","optional":true,"default":"nil","nullable":true},{"name":"jagged_rows","types":["Boolean"],"description":"Accept rows that are missing trailing\noptional columns. The missing values are treated as nulls. If <code>false</code>,\nrecords with missing trailing columns are treated as bad records, and\nif there are too many bad records, an invalid error is returned in the\njob result. The default value is <code>false</code>. Only applicable to CSV,\nignored for other formats.","optional":true,"default":"nil","nullable":true},{"name":"quoted_newlines","types":["Boolean"],"description":"Indicates if BigQuery should allow\nquoted data sections that contain newline characters in a CSV file.\nThe default value is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"encoding","types":["String"],"description":"The character encoding of the data. The\nsupported values are <code>UTF-8</code> or <code>ISO-8859-1</code>. The default value is\n<code>UTF-8</code>.","optional":true,"default":"nil","nullable":true},{"name":"delimiter","types":["String"],"description":"Specifices the separator for fields in a CSV\nfile. BigQuery converts the string to <code>ISO-8859-1</code> encoding, and then\nuses the first byte of the encoded string to split the data in its\nraw, binary state. Default is <code>,</code>.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Indicates if BigQuery should allow extra\nvalues that are not represented in the table schema. If true, the\nextra values are ignored. If false, records with extra columns are\ntreated as bad records, and if there are too many bad records, an\ninvalid error is returned in the job result. The default value is\n<code>false</code>.</p>\n\n<p>The <code>format</code> property determines what BigQuery treats as an extra\nvalue:</p>\n\n<ul>\n  <li><code>CSV</code>: Trailing columns</li>\n  <li><code>JSON</code>: Named values that don’t match any column names</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"max_bad_records","types":["Integer"],"description":"The maximum number of bad records that\nBigQuery can ignore when running the job. If the number of bad records\nexceeds this value, an invalid error is returned in the job result.\nThe default value is <code>0</code>, which requires that all records are valid.","optional":true,"default":"nil","nullable":true},{"name":"quote","types":["String"],"description":"The value that is used to quote data sections in a\nCSV file. BigQuery converts the string to ISO-8859-1 encoding, and\nthen uses the first byte of the encoded string to split the data in\nits raw, binary state. The default value is a double-quote\n<code>\"</code>. If your data does not contain quoted sections, set the\nproperty value to an empty string. If your data contains quoted\nnewline characters, you must also set the allowQuotedNewlines property\nto true.","optional":true,"default":"nil","nullable":true},{"name":"skip_leading","types":["Integer"],"description":"The number of rows at the top of a CSV\nfile that BigQuery will skip when loading the data. The default value\nis <code>0</code>. This property is useful if you have header rows in the file\nthat should be skipped.","optional":true,"default":"nil","nullable":true},{"name":"chunk_size","types":["Integer"],"description":"The number of bytes per chunk in a resumable\nupload. Must be divisible by 256KB. If it is not divisible by 265KB\nthen it will be lowered to the nearest acceptable value. If no value\nis provided it will use <a data-custom-type=\"gcloud/upload\" data-method=\"default_chunk_size-class\">Gcloud::Upload.default_chunk_size</a>. Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"gcloud/bigquery/loadjob\">Gcloud::Bigquery::LoadJob</a>"],"description":""}]},{"id":"insert-instance","type":"instance","name":"insert","title":["Gcloud","Bigquery","Table#insert"],"description":"<p>Inserts data into the table for near-immediate querying, without the\nneed to complete a #load operation before the data can appear in query\nresults.</p>","source":"lib/gcloud/bigquery/table.rb#L810","resources":[{"title":"Streaming Data Into BigQuery","link":"https://cloud.google.com/bigquery/streaming-data-into-bigquery"}],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\nrows = [\n  { \"first_name\" => \"Alice\", \"age\" => 21 },\n  { \"first_name\" => \"Bob\", \"age\" => 22 }\n]\ntable.insert rows"}],"params":[{"name":"rows","types":["Hash","Array<Hash>"],"description":"A hash object or array of hash objects\ncontaining the data.","optional":false,"nullable":false},{"name":"skip_invalid","types":["Boolean"],"description":"Insert all valid rows of a request, even\nif invalid rows exist. The default value is <code>false</code>, which causes the\nentire request to fail if any invalid rows exist.","optional":true,"default":"nil","nullable":true},{"name":"ignore_unknown","types":["Boolean"],"description":"Accept rows that contain values that do\nnot match the schema. The unknown values are ignored. Default is\nfalse, which treats unknown values as errors.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"gcloud/bigquery/insertresponse\">Gcloud::Bigquery::InsertResponse</a>"],"description":""}]},{"id":"delete-instance","type":"instance","name":"delete","title":["Gcloud","Bigquery","Table#delete"],"description":"<p>Permanently deletes the table.</p>","source":"lib/gcloud/bigquery/table.rb#L839","resources":[],"examples":[{"caption":"","code":"require \"gcloud\"\n\ngcloud = Gcloud.new\nbigquery = gcloud.bigquery\ndataset = bigquery.dataset \"my_dataset\"\ntable = dataset.table \"my_table\"\n\ntable.delete"}],"params":[],"exceptions":[],"returns":[{"types":["Boolean"],"description":"Returns <code>true</code> if the table was deleted."}]},{"id":"reload!-instance","type":"instance","name":"reload!","title":["Gcloud","Bigquery","Table#reload!"],"description":"<p>Reloads the table with current data from the BigQuery service.</p>","source":"lib/gcloud/bigquery/table.rb#L854","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]}]}