{"id":"google/cloud/speech/project","name":"Project","title":["Google","Cloud","Speech","Project"],"description":"<h1 id=\"project\">Project</h1>\n\n<p>The Google Cloud Speech API enables developers to convert audio to text\nby applying powerful neural network models. The API recognizes over 80\nlanguages and variants, to support your global user base. You can\ntranscribe the text of users dictating to an application’s microphone,\nenable command-and-control through voice, or transcribe audio files,\namong many other use cases. Recognize audio uploaded in the request, and\nintegrate with your audio storage on Google Cloud Storage, by using the\nsame technology Google uses to power its own products.</p>\n\n<p>See <a data-custom-type=\"google/cloud\" data-method=\"speech-instance\">Google::Cloud#speech</a></p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L54","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000\nresults = audio.recognize\n\nresult = results.first\nresult.transcript #=> \"how old is the Brooklyn Bridge\"\nresult.confidence #=> 0.9826789498329163"}],"methods":[{"id":"project-instance","type":"instance","name":"project","title":["Google","Cloud","Speech","Project#project"],"description":"<p>The Speech project connected to.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L77","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new(\n  project: \"my-project-id\",\n  keyfile: \"/path/to/keyfile.json\"\n)\n\nspeech.project #=> \"my-project-id\""}],"params":[],"exceptions":[],"returns":[]},{"id":"audio-instance","type":"instance","name":"audio","title":["Google","Cloud","Speech","Project#audio"],"description":"<p>Returns a new Audio instance from the given source. No API call is\nmade.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L168","resources":[{"title":"Audio Encodings","link":"https://cloud.google.com/speech/docs/basics#audio-encodings"},{"title":"Sample Rates","link":"https://cloud.google.com/speech/docs/basics#sample-rates"},{"title":"Languages","link":"https://cloud.google.com/speech/docs/basics#languages"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage URI:</p>","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"gs://bucket-name/path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage File object:</p>","code":"require \"google/cloud/storage\"\n\nstorage = Google::Cloud::Storage.new\n\nbucket = storage.bucket \"bucket-name\"\nfile = bucket.file \"path/to/audio.raw\"\n\nrequire \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio file, encoding: :raw, sample_rate: 16000"}],"params":[{"name":"source","types":["String","IO","Google::Cloud::Storage::File"],"description":"A string of\nthe path to the audio file to be recognized, or a File or other IO\nobject of the audio contents, or a Cloud Storage URI of the form\n<code>\"gs://bucketname/path/to/document.ext\"</code>; or an instance of\nGoogle::Cloud::Storage::File of the text to be annotated.","optional":false,"nullable":false},{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>raw</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String"],"description":"The language of the supplied audio as a\n<a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language\ncode. If not specified, the language defaults to “en-US”.  See\n<a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a>\nfor a list of the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/audio\">Audio</a>"],"description":"The audio file to be recognized."}]},{"id":"recognize-instance","type":"instance","name":"recognize","title":["Google","Cloud","Speech","Project#recognize"],"description":"<p>Performs synchronous speech recognition. Sends audio data to the\nSpeech API, which performs recognition on that data, and returns\nresults only after all audio has been processed. Limited to audio data\nof 1 minute or less in duration.</p>\n\n<p>The Speech API will take roughly the same amount of time to process\naudio data sent synchronously as the duration of the supplied audio\ndata. That is, if you send audio data of 30 seconds in length, expect\nthe synchronous request to take approximately 30 seconds to return\nresults.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L277","resources":[{"title":"Synchronous Speech API Recognition","link":"https://cloud.google.com/speech/docs/basics#synchronous-recognition"},{"title":"Phrase Hints","link":"https://cloud.google.com/speech/docs/basics#phrase-hints"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nresults = speech.recognize \"path/to/audio.raw\",\n                           encoding: :raw, sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage URI:</p>","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nresults = speech.recognize \"gs://bucket-name/path/to/audio.raw\",\n                           encoding: :raw, sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage File object:</p>","code":"require \"google/cloud/storage\"\n\nstorage = Google::Cloud::Storage.new\n\nbucket = storage.bucket \"bucket-name\"\nfile = bucket.file \"path/to/audio.raw\"\n\nrequire \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nresults = speech.recognize file, encoding: :raw,\n                           sample_rate: 16000,\n                           max_alternatives: 10"}],"params":[{"name":"source","types":["String","IO","Google::Cloud::Storage::File"],"description":"A string of\nthe path to the audio file to be recognized, or a File or other IO\nobject of the audio contents, or a Cloud Storage URI of the form\n<code>\"gs://bucketname/path/to/document.ext\"</code>; or an instance of\nGoogle::Cloud::Storage::File of the text to be annotated.","optional":false,"nullable":false},{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>raw</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String"],"description":"The language of the supplied audio as a\n<a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language\ncode. If not specified, the language defaults to “en-US”.  See\n<a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a>\nfor a list of the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true},{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/speech/result\">Result</a>&gt;"],"description":"The transcribed text of audio recognized."}]},{"id":"recognize_job-instance","type":"instance","name":"recognize_job","title":["Google","Cloud","Speech","Project#recognize_job"],"description":"<p>Performs asynchronous speech recognition. Requests are processed\nasynchronously, meaning a Job is returned once the audio data has been\nsent, and can be refreshed to retrieve recognition results once the\naudio data has been processed.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L384","resources":[{"title":"Asynchronous Speech API Responses","link":"https://cloud.google.com/speech/docs/basics#async-responses"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\njob = speech.recognize_job \"path/to/audio.raw\",\n                           encoding: :raw, sample_rate: 16000\n\njob.done? #=> false\njob.reload!"},{"caption":"<p>With a Google Cloud Storage URI:</p>","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\njob = speech.recognize_job \"gs://bucket-name/path/to/audio.raw\",\n                           encoding: :raw, sample_rate: 16000\n\njob.done? #=> false\njob.reload!"},{"caption":"<p>With a Google Cloud Storage File object:</p>","code":"require \"google/cloud/storage\"\n\nstorage = Google::Cloud::Storage.new\n\nbucket = storage.bucket \"bucket-name\"\nfile = bucket.file \"path/to/audio.raw\"\n\nrequire \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\njob = speech.recognize_job file, encoding: :raw,\n                           sample_rate: 16000,\n                           max_alternatives: 10\n\njob.done? #=> false\njob.reload!"}],"params":[{"name":"source","types":["String","IO","Google::Cloud::Storage::File"],"description":"A string of\nthe path to the audio file to be recognized, or a File or other IO\nobject of the audio contents, or a Cloud Storage URI of the form\n<code>\"gs://bucketname/path/to/document.ext\"</code>; or an instance of\nGoogle::Cloud::Storage::File of the text to be annotated.","optional":false,"nullable":false},{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Currently, the only acceptable value is:</p>\n\n<ul>\n  <li><code>raw</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String"],"description":"The language of the supplied audio as a\n<a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language\ncode. If not specified, the language defaults to “en-US”.  See\n<a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a>\nfor a list of the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true},{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/job\">Job</a>"],"description":"A resource represents the long-running, asynchronous\nprocessing of a speech-recognition operation."}]},{"id":"stream-instance","type":"instance","name":"stream","title":["Google","Cloud","Speech","Project#stream"],"description":"<p>Creates a Stream object to perform bidirectional streaming\nspeech-recognition: receive results while sending audio.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L482","resources":[{"title":"Streaming Speech API Recognition Requests","link":"https://cloud.google.com/speech/docs/basics#streaming-recognition"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nstream = speech.stream encoding: :raw, sample_rate: 16000\n\n# register callback for when a result is returned\nstream.on_result do |results|\n  result = results.first\n  puts result.transcript # \"how old is the Brooklyn Bridge\"\n  puts result.confidence # 0.9826789498329163\nend\n\n# Stream 5 seconds of audio from the microphone\n# Actual implementation of microphone input varies by platform\n5.times do\n  stream.send MicrophoneInput.read(32000)\nend\n\nstream.stop"}],"params":[{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>raw</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String"],"description":"The language of the supplied audio as a\n<a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language\ncode. If not specified, the language defaults to “en-US”.  See\n<a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a>\nfor a list of the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true},{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true},{"name":"utterance","types":["Boolean"],"description":"When <code>true</code>, the service will perform\ncontinuous recognition (continuing to process audio even if the user\npauses speaking) until the client closes the output stream (gRPC\nAPI) or when the maximum time limit has been reached. Default is\n<code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"interim","types":["Boolean"],"description":"When <code>true</code>, interim results (tentative\nhypotheses) may be returned as they become available. Default is\n<code>false</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/stream\">Stream</a>"],"description":"A resource that represents the streaming requests and\nresponses."}]}]}