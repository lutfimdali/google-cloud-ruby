{"id":"google/cloud/speech","name":"Speech","title":["Google","Cloud","Speech"],"description":"<h1 id=\"google-cloud-speech\">Google Cloud Speech</h1>\n\n<p>Google Cloud Speech API enables developers to convert audio to text by\napplying powerful neural network models in an easy to use API. The API\nrecognizes over 80 languages and variants, to support your global user\nbase. You can transcribe the text of users dictating to an applicationâ€™s\nmicrophone, enable command-and-control through voice, or transcribe audio\nfiles, among many other use cases. Recognize audio uploaded in the\nrequest, and integrate with your audio storage on Google Cloud Storage, by\nusing the same technology Google uses to power its own products.</p>\n\n<p>For more information about Google Cloud Speech API, read the <a href=\"https://cloud.google.com/speech/docs/\">Google Cloud\nSpeech API Documentation</a>.</p>\n\n<p>The goal of google-cloud is to provide an API that is comfortable to\nRubyists. Authentication is handled by <a data-custom-type=\"google/cloud\" data-method=\"speech-instance\">Google::Cloud#speech</a>. You can\nprovide the project and credential information to connect to the Cloud\nSpeech service, or if you are running on Google Compute Engine this\nconfiguration is taken care of for you. You can read more about the\noptions for connecting in the <a href=\"https://googlecloudplatform.github.io/google-cloud-ruby/#/docs/guides/authentication\">Authentication\nGuide</a>.</p>\n\n<h2 id=\"creating-audio-sources\">Creating audio sources</h2>\n\n<p>You can create an audio object that holds a reference to any one of\nseveral types of audio data source, along with metadata such as the audio\nencoding type.</p>\n\n<p>Use <a data-custom-type=\"google/cloud/speech/project\" data-method=\"audio-instance\">Speech::Project#audio</a> to create audio sources for the Cloud Speech\nAPI. You can provide a file path:</p>\n\n<pre><code class=\"language-ruby\">require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000\n</code></pre>\n\n<p>Or, you can initialize the audio instance with a Google Cloud Storage URI:</p>\n\n<pre><code class=\"language-ruby\">require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"gs://bucket-name/path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000\n</code></pre>\n\n<p>Or, with a Google Cloud Storage File object:</p>\n\n<pre><code class=\"language-ruby\">require \"google/cloud/storage\"\n\nstorage = Google::Cloud::Storage.new\n\nbucket = storage.bucket \"bucket-name\"\nfile = bucket.file \"path/to/audio.raw\"\n\nrequire \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio file, encoding: :raw, sample_rate: 16000\n</code></pre>\n\n<h2 id=\"recognizing-speech\">Recognizing speech</h2>\n\n<p>The instance methods on <a data-custom-type=\"google/cloud/speech/audio\">Speech::Audio</a> can be used to invoke both\nsynchronous and asynchronous versions of the Cloud Speech API speech\nrecognition operation.</p>\n\n<p>Use <a data-custom-type=\"google/cloud/speech/audio\" data-method=\"recognize-instance\">Speech::Audio#recognize</a> for synchronous speech recognition that\nreturns <a data-custom-type=\"google/cloud/speech/result\">Speech::Result</a> objects only after all audio has been processed.\nThis method is limited to audio data of 1 minute or less in duration, and\nwill take roughly the same amount of time to process as the duration of\nthe supplied audio data.</p>\n\n<pre><code class=\"language-ruby\">require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000\nresults = audio.recognize\n\nresult = results.first\nresult.transcript #=&gt; \"how old is the Brooklyn Bridge\"\nresult.confidence #=&gt; 0.9826789498329163\n</code></pre>\n\n<p>Use <a data-custom-type=\"google/cloud/speech/audio\" data-method=\"recognize_job-instance\">Speech::Audio#recognize_job</a> for asynchronous speech recognition,\nin which a <a data-custom-type=\"google/cloud/speech/job\">Speech::Job</a> is returned immediately after the audio data has\nbeen sent. The job can be refreshed to retrieve <a data-custom-type=\"google/cloud/speech/result\">Speech::Result</a> objects\nonce the audio data has been processed.</p>\n\n<pre><code class=\"language-ruby\">require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000\njob = audio.recognize_job\n\njob.done? #=&gt; false\njob.reload!\njob.done? #=&gt; true\nresults = job.results\n\nresult = results.first\nresult.transcript #=&gt; \"how old is the Brooklyn Bridge\"\nresult.confidence #=&gt; 0.9826789498329163\n</code></pre>\n\n<p>Use <a data-custom-type=\"google/cloud/speech/project\" data-method=\"stream-instance\">Speech::Project#stream</a> for streaming audio data for speech\nrecognition, in which a <a data-custom-type=\"google/cloud/speech/stream\">Speech::Stream</a> is returned. The stream object\ncan receive results while sending audio by performing bidirectional\nstreaming speech-recognition.</p>\n\n<pre><code class=\"language-ruby\">require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\"\n\nstream = audio.stream encoding: :raw, sample_rate: 16000\n\n# register callback for when a result is returned\nstream.on_result do |results|\n  result = results.first\n  result.transcript #=&gt; \"how old is the Brooklyn Bridge\"\n  result.confidence #=&gt; 0.9826789498329163\nend\n\n# Stream 5 seconds of audio from the microhone\n# Actual implementation of microphone input varies by platform\n5.times.do\n  stream.send MicrophoneInput.read(32000)\nend\n\nstream.stop\n</code></pre>\n\n<p>Obtaining audio data from input sources such as a Microphone is outside\nthe scope of this document.</p>","source":"google-cloud-speech/lib/google/cloud/speech.rb#L173","resources":[],"examples":[],"methods":[{"id":"new-class","type":"class","name":"new","title":["Google","Cloud","Speech.new"],"description":"<p>Creates a new object for connecting to the Speech service.\nEach call creates a new connection.</p>\n\n<p>For more information on connecting to Google Cloud see the\n<a href=\"https://googlecloudplatform.github.io/google-cloud-ruby/#/docs/guides/authentication\">Authentication\nGuide</a>.</p>","source":"google-cloud-speech/lib/google/cloud/speech.rb#L208","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :raw, sample_rate: 16000"}],"params":[{"name":"project","types":["String"],"description":"Project identifier for the Speech service you\nare connecting to.","optional":true,"default":"nil","nullable":true},{"name":"keyfile","types":["String","Hash"],"description":"Keyfile downloaded from Google Cloud. If\nfile path the file must be readable.","optional":true,"default":"nil","nullable":true},{"name":"scope","types":["String","Array<String>"],"description":"The OAuth 2.0 scopes controlling\nthe set of resources and operations that the connection can access.\nSee <a href=\"https://developers.google.com/identity/protocols/OAuth2\">Using OAuth 2.0 to Access Google\nAPIs</a>.</p>\n\n<p>The default scope is:</p>\n\n<ul>\n  <li><code>https://www.googleapis.com/auth/speech</code></li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"timeout","types":["Integer"],"description":"Default timeout to use in requests. Optional.","optional":true,"default":"nil","nullable":true},{"name":"client_config","types":["Hash"],"description":"A hash of values to override the default\nbehavior of the API client. Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/project\">Google::Cloud::Speech::Project</a>"],"description":""}]}]}